{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @NOTE: 原始数据读取在extractFeture.py中\n",
    "#from data import extractFeture\n",
    "import time\n",
    "import numpy as np \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from src.data.loaddata import load_data\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔵 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o:\\eeg\\epilepsy_EEG_analysis_code\n",
      "Loading data for subject 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading EDF files:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from o:\\eeg\\epilepsy_EEG_analysis_code\\src\\data\\chb01\\chb01_03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "o:\\eeg\\epilepsy_EEG_analysis_code\\src\\data\\extractFeture.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(file_name, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 50 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 50.00 Hz\n",
      "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
      "- Filter length: 845 samples (3.301 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing windows:  20%|█▉        | 178/900 [04:20<17:34,  1.46s/it]\n",
      "Loading EDF files:   0%|          | 0/1 [04:21<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data for subject \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 加载数据\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m all_X\u001b[38;5;241m.\u001b[39mappend(X)\n\u001b[0;32m     19\u001b[0m all_y\u001b[38;5;241m.\u001b[39mappend(y)\n",
      "File \u001b[1;32mo:\\eeg\\epilepsy_EEG_analysis_code\\src\\data\\loaddata.py:138\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(subject_id, base_path)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# 使用tqdm包装迭代器以显示进度条\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m edf_file_path \u001b[38;5;129;01min\u001b[39;00m tqdm(edf_file_paths, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading EDF files\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 138\u001b[0m     X1d, X2d, y, y2d \u001b[38;5;241m=\u001b[39m \u001b[43mextract_data_and_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43medf_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m     all_X1d\u001b[38;5;241m.\u001b[39mappend(X1d)\n\u001b[0;32m    140\u001b[0m     all_X2d\u001b[38;5;241m.\u001b[39mappend(X2d)\n",
      "File \u001b[1;32mo:\\eeg\\epilepsy_EEG_analysis_code\\src\\data\\loaddata.py:102\u001b[0m, in \u001b[0;36mextract_data_and_labels\u001b[1;34m(edf_file_path, summary_file_path)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_data_and_labels\u001b[39m(edf_file_path, summary_file_path):\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# 提取特征\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# @DATA: X.shape = (20700,19) = (900 * 23, 19) = (3600/4 * 23, 18+1)\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_and_extract_features_mne_with_timestamps\u001b[49m\u001b[43m(\u001b[49m\u001b[43medf_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# 提取标签\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     seizure_start_time, seizure_end_time \u001b[38;5;241m=\u001b[39m extractTarget(summary_file_path, edf_file_path)\n",
      "File \u001b[1;32mo:\\eeg\\epilepsy_EEG_analysis_code\\src\\data\\extractFeture.py:162\u001b[0m, in \u001b[0;36mpreprocess_and_extract_features_mne_with_timestamps\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m    160\u001b[0m advanced_features \u001b[38;5;241m=\u001b[39m extract_advanced_features(channel_data, sfreq)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# @DATA: wavelet_features.shape = (18,)\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m wavelet_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_wavelet_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannel_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msfreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# @DATA: combined_features.shape = (392,)\u001b[39;00m\n\u001b[0;32m    164\u001b[0m combined_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([[timestamp], advanced_features, wavelet_features])\n",
      "File \u001b[1;32mo:\\eeg\\epilepsy_EEG_analysis_code\\src\\data\\extractFeture.py:99\u001b[0m, in \u001b[0;36mextract_wavelet_features\u001b[1;34m(signal, sfreq)\u001b[0m\n\u001b[0;32m     96\u001b[0m band_energy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39msquare(subband))\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# 计算模糊熵\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m fuzzyEn \u001b[38;5;241m=\u001b[39m \u001b[43mfuzzy_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubband\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m fuzzyEn \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(fuzzyEn)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# 将特征添加到列表中\u001b[39;00m\n",
      "File \u001b[1;32mo:\\eeg\\epilepsy_EEG_analysis_code\\src\\data\\extractFeture.py:74\u001b[0m, in \u001b[0;36mextract_wavelet_features.<locals>.fuzzy_entropy\u001b[1;34m(signal, m, r)\u001b[0m\n\u001b[0;32m     71\u001b[0m     C \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mabs(x[:, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m-\u001b[39m x[\u001b[38;5;28;01mNone\u001b[39;00m, :])\u001b[38;5;241m.\u001b[39mmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m (N \u001b[38;5;241m-\u001b[39m m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m C\n\u001b[1;32m---> 74\u001b[0m phi_m \u001b[38;5;241m=\u001b[39m \u001b[43m_phi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m phi_m1 \u001b[38;5;241m=\u001b[39m _phi(m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# 截取较长的数组以匹配较短数组的长度\u001b[39;00m\n",
      "File \u001b[1;32mo:\\eeg\\epilepsy_EEG_analysis_code\\src\\data\\extractFeture.py:71\u001b[0m, in \u001b[0;36mextract_wavelet_features.<locals>.fuzzy_entropy.<locals>._phi\u001b[1;34m(m)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_phi\u001b[39m(m):\n\u001b[0;32m     70\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([signal[i:i \u001b[38;5;241m+\u001b[39m m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N \u001b[38;5;241m-\u001b[39m m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)])\n\u001b[1;32m---> 71\u001b[0m     C \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m (N \u001b[38;5;241m-\u001b[39m m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m C\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 记录数据预处理开始时间\n",
    "data_preprocess_start_time = time.time()\n",
    "\n",
    "\n",
    "subject_ids = [1,2,3]\n",
    "# 打印当前目录\n",
    "print(os.getcwd())\n",
    "base_path = \"src/data\" # 数据存放路径\n",
    "# 初始化 all_X 和 all_y 为空列表，用于存储所有主题的 X 和 y 数据\n",
    "all_X = []\n",
    "all_y = []\n",
    "\n",
    "# 遍历所有主题\n",
    "for subject_id in subject_ids:\n",
    "    print(f\"Loading data for subject {subject_id}...\")\n",
    "    # 加载数据\n",
    "    X, y = load_data(subject_id, base_path)\n",
    "    all_X.append(X)\n",
    "    all_y.append(y)\n",
    "\n",
    "\n",
    "# @TODO:23个通道的特征只是简单的拼接在一起，没有用到通道之间的关系\n",
    "# 合并 all_X 和 all_y, vstack是垂直合并, concatenate是水平合并\n",
    "# @DATA: X.shape = (27600,18), y.shape = (27600,) # (27600,18) -> (1200 , 23, 18) -> (1200 , 23 , 6 , 3)\n",
    "X = np.vstack(all_X)\n",
    "# @DATA: y.shape = (27600,)\n",
    "y = np.concatenate(all_y)\n",
    "\n",
    "# 记录数据预处理结束时间\n",
    "data_preprocess_end_time = time.time()\n",
    "\n",
    "# 计算数据预处理耗时\n",
    "data_preprocess_time = data_preprocess_end_time - data_preprocess_start_time\n",
    "print(f\"Data preprocess time: {data_preprocess_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampling time: 0.31 seconds\n"
     ]
    }
   ],
   "source": [
    "# 记录过采样开始时间\n",
    "oversampling_start_time = time.time()\n",
    "\n",
    "# 初始化 SMOTE 实例\n",
    "smote = SMOTE()\n",
    "\n",
    "# @NOTE: SMOTE: Synthetic Minority Over-sampling Technique\n",
    "# 1. 找到标签 y 中的少数类（例如 y=1）\n",
    "# 2. 在少数类样本的特征空间中，通过现有样本之间的插值生成新的样本\n",
    "# 3. 生成的新样本与少数类样本相似，从而增加少数类样本数量，平衡类别分布\n",
    "\n",
    "# 应用 SMOTE 过采样\n",
    "# @NOTE: 过采样平衡数据\n",
    "# @NOTE: 过采样：对少数类样本进行插值，增加样本数量，使得少数类样本与多数类样本数量接近相等（不超原数据两倍）\n",
    "# @NOTE: y = 1/0\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# 记录过采样结束时间\n",
    "oversampling_end_time = time.time()\n",
    "\n",
    "# 计算过采样耗时\n",
    "oversampling_time = oversampling_end_time - oversampling_start_time\n",
    "print(f\"Oversampling time: {oversampling_time:.2f} seconds\")\n",
    "\n",
    "# 分割处理后的数据集\n",
    "# @TODO:了解数据内容与格式\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=0)\n",
    "# @DATA: X_train.shape = (*,391), X_test.shape = (*,391), y_train.shape = (*,), y_test.shape = (*,)\n",
    "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape) # (38189, 391) (16367, 391) (38189,) (16367,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.75 seconds\n",
      "Accuracy: 0.9776379299810595\n",
      "F1 分数: 0.9777318082258457\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 记录训练开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 训练决策树分类器\n",
    "# @IDEA:换成1DCNN\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 记录训练结束时间\n",
    "end_time = time.time()\n",
    "\n",
    "# 计算训练耗时\n",
    "train_time = end_time - start_time\n",
    "print(f\"Training time: {train_time:.2f} seconds\")\n",
    "\n",
    "# 对测试集进行预测\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 计算 F1 分数\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 分数: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310no1",
   "language": "python",
   "name": "py310no1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
